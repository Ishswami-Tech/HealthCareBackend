# Continuous Integration Workflow - Docker Only
name: CI/CD

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [develop, main]
    paths-ignore:
      - 'README.md'
      - '**/*.md'
      - '**/*.svg'

permissions:
  contents: read
  pull-requests: write
  checks: write
  packages: write
  security-events: write  # Required for CodeQL SARIF upload
  actions: read  # Required for CodeQL to access workflow run information

env:
  NODE_VERSION: '20'
  YARN_VERSION: '1.22.22'
  REGISTRY: ghcr.io
  IMAGE_REPO: ${{ github.repository }}
  IMAGE_NAME: healthcare-api
  # Note: IMAGE will be set in docker-build job with lowercase conversion

jobs:
  # Code Quality Checks
  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'

      - name: Install Yarn
        run: npm install -g yarn@${{ env.YARN_VERSION }}

      - name: Install dependencies
        run: yarn install --frozen-lockfile

      - name: Run ESLint
        run: yarn lint

      - name: Check code formatting
        run: yarn format:check

  # Security Scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        continue-on-error: true  # Don't fail if Advanced Security is not enabled
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Dependency Check
        run: |
          npx audit-ci --moderate

  # TypeScript Build
  # Docker Build & Push
  # Note: Build happens inside Docker, no separate build job needed
  docker-build:
    name: Docker Build & Push
    runs-on: ubuntu-latest
    needs: [lint, security]  # Build happens inside Docker, no separate build job needed
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set image name (lowercase)
        id: image
        run: |
          REPO_LOWER=$(echo "${{ env.IMAGE_REPO }}" | tr '[:upper:]' '[:lower:]')
          IMAGE_FULL="ghcr.io/${REPO_LOWER}/${{ env.IMAGE_NAME }}"
          echo "image=${IMAGE_FULL}" >> $GITHUB_OUTPUT
          echo "Image name: ${IMAGE_FULL}"

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.image.outputs.image }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: devops/docker/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      - name: Output image digest
        run: |
          echo "Image pushed: ${{ steps.meta.outputs.tags }}"

  # Change Detection
  detect-changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    outputs:
      infra-changed: ${{ steps.filter.outputs.infra }}
      app-changed: ${{ steps.filter.outputs.app }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Detect infrastructure and application changes
        uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            infra:
              - 'devops/docker/Dockerfile.postgres'
              - 'devops/docker/Dockerfile.dragonfly'
              - 'devops/docker/Dockerfile.openvidu'
              - 'devops/docker/docker-compose.prod.yml'
              - 'prisma/migrations/**'
            app:
              - 'src/**'
              - 'package.json'
              - 'yarn.lock'
              - 'tsconfig.json'
              - 'devops/docker/Dockerfile'

      - name: Output changes
        run: |
          echo "Infrastructure changed: ${{ steps.filter.outputs.infra }}"
          echo "Application changed: ${{ steps.filter.outputs.app }}"

  # Infrastructure Health Check
  check-infrastructure:
    name: Check Infrastructure Health
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: production
    needs: [detect-changes]
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Copy health check script
        run: |
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/docker-infra/health-check.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/health-check.sh
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/shared/utils.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/utils.sh

      - name: Run health check
        id: health-check
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            chmod +x /tmp/health-check.sh /tmp/utils.sh
            export SCRIPT_DIR="/tmp"
            source /tmp/utils.sh
            /tmp/health-check.sh > /tmp/health-status.json
            echo "EXIT_CODE=$?" > /tmp/health-exit.txt
          ENDSSH
          
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/health-status.json /tmp/health-status.json || true
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/health-exit.txt /tmp/health-exit.txt || true
          
          if [[ -f /tmp/health-exit.txt ]]; then
            EXIT_CODE=$(cat /tmp/health-exit.txt | grep EXIT_CODE | cut -d= -f2)
            if [[ "$EXIT_CODE" == "0" ]]; then
              echo "infra-healthy=true" >> $GITHUB_OUTPUT
              echo "infra-status=healthy" >> $GITHUB_OUTPUT
            else
              echo "infra-healthy=false" >> $GITHUB_OUTPUT
              if [[ "$EXIT_CODE" == "3" ]]; then
                echo "infra-status=missing" >> $GITHUB_OUTPUT
              else
                echo "infra-status=unhealthy" >> $GITHUB_OUTPUT
              fi
            fi
          else
            echo "infra-healthy=false" >> $GITHUB_OUTPUT
            echo "infra-status=unknown" >> $GITHUB_OUTPUT
          fi

      - name: Display health status
        run: |
          echo "Infrastructure Health: ${{ steps.health-check.outputs.infra-healthy }}"
          echo "Infrastructure Status: ${{ steps.health-check.outputs.infra-status }}"
          if [[ -f /tmp/health-status.json ]]; then
            cat /tmp/health-status.json
          fi

  # Backup Infrastructure
  backup-infrastructure:
    name: Backup Infrastructure
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main' && 
      (needs.detect-changes.outputs.infra-changed == 'true' || 
       needs.check-infrastructure.outputs.infra-healthy == 'false')
    environment: production
    needs: [detect-changes, check-infrastructure]
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Copy backup scripts
        run: |
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/docker-infra/backup.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/backup.sh
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/shared/utils.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/utils.sh

      - name: Run backup
        id: backup
        env:
          S3_ENABLED: ${{ vars.S3_ENABLED }}
          S3_PROVIDER: ${{ vars.S3_PROVIDER }}
          S3_ENDPOINT: ${{ vars.S3_ENDPOINT }}
          S3_REGION: ${{ vars.S3_REGION }}
          S3_BUCKET: ${{ vars.S3_BUCKET }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_FORCE_PATH_STYLE: ${{ vars.S3_FORCE_PATH_STYLE }}
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            export SCRIPT_DIR="/tmp"
            source /tmp/utils.sh
            export S3_ENABLED="${{ vars.S3_ENABLED }}"
            export S3_PROVIDER="${{ vars.S3_PROVIDER }}"
            export S3_ENDPOINT="${{ vars.S3_ENDPOINT }}"
            export S3_REGION="${{ vars.S3_REGION }}"
            export S3_BUCKET="${{ vars.S3_BUCKET }}"
            export S3_ACCESS_KEY_ID="${{ secrets.S3_ACCESS_KEY_ID }}"
            export S3_SECRET_ACCESS_KEY="${{ secrets.S3_SECRET_ACCESS_KEY }}"
            export S3_FORCE_PATH_STYLE="${{ vars.S3_FORCE_PATH_STYLE }}"
            chmod +x /tmp/backup.sh
            BACKUP_ID=\$(/tmp/backup.sh)
            echo "BACKUP_ID=\${BACKUP_ID}" > /tmp/backup-id.txt
          ENDSSH
          
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/backup-id.txt /tmp/backup-id.txt
          BACKUP_ID=\$(grep BACKUP_ID /tmp/backup-id.txt | cut -d= -f2)
          echo "backup-id=\${BACKUP_ID}" >> $GITHUB_OUTPUT
          echo "Backup ID: \${BACKUP_ID}"

  # Debug Infrastructure
  debug-infrastructure:
    name: Debug Infrastructure
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main' && 
      needs.check-infrastructure.outputs.infra-healthy == 'false' &&
      needs.detect-changes.outputs.infra-changed != 'true'
    environment: production
    needs: [detect-changes, check-infrastructure]
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Copy diagnostic scripts
        run: |
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/docker-infra/diagnose.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/diagnose.sh
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/shared/utils.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/utils.sh

      - name: Run diagnostics and auto-fix
        id: debug
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            export SCRIPT_DIR="/tmp"
            source /tmp/utils.sh
            chmod +x /tmp/diagnose.sh
            if /tmp/diagnose.sh > /tmp/debug-result.json 2>&1; then
              echo "debug-status=fixed" > /tmp/debug-status.txt
            else
              echo "debug-status=failed" > /tmp/debug-status.txt
            fi
          ENDSSH
          
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/debug-status.txt /tmp/debug-status.txt
          DEBUG_STATUS=\$(grep debug-status /tmp/debug-status.txt | cut -d= -f2)
          echo "debug-status=\${DEBUG_STATUS}" >> $GITHUB_OUTPUT

  # Recreate Infrastructure
  recreate-infrastructure:
    name: Recreate Infrastructure
    runs-on: ubuntu-latest
    if: |
      always() &&
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main' && 
      (needs.detect-changes.outputs.infra-changed == 'true' || 
       (needs.check-infrastructure.outputs.infra-healthy == 'false' && 
        (needs.debug-infrastructure.result == 'failure' || needs.debug-infrastructure.result == 'skipped')))
    environment: production
    needs: [detect-changes, check-infrastructure, backup-infrastructure, debug-infrastructure]
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Recreate infrastructure containers
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            set -e
            cd /opt/healthcare-backend/devops/docker || exit 1
            
            # Stop existing infrastructure containers gracefully
            echo "Stopping existing infrastructure containers..."
            docker compose -f docker-compose.prod.yml --profile infrastructure stop || true
            
            # Recreate infrastructure containers
            echo "Recreating infrastructure containers..."
            docker compose -f docker-compose.prod.yml --profile infrastructure up -d
            
            # Wait for containers to be healthy
            echo "Waiting for infrastructure containers to be healthy..."
            sleep 10
            
            # Check container status
            docker compose -f docker-compose.prod.yml --profile infrastructure ps
          ENDSSH

  # Restore Backup
  restore-backup:
    name: Restore Backup
    runs-on: ubuntu-latest
    if: |
      always() &&
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main' && 
      needs.backup-infrastructure.result == 'success' &&
      needs.backup-infrastructure.outputs.backup-id != ''
    environment: production
    needs: [backup-infrastructure, recreate-infrastructure]
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Copy restore scripts
        run: |
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/docker-infra/restore.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/restore.sh
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/shared/utils.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/utils.sh

      - name: Restore from backup
        env:
          S3_ENABLED: ${{ vars.S3_ENABLED }}
          S3_PROVIDER: ${{ vars.S3_PROVIDER }}
          S3_ENDPOINT: ${{ vars.S3_ENDPOINT }}
          S3_REGION: ${{ vars.S3_REGION }}
          S3_BUCKET: ${{ vars.S3_BUCKET }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_FORCE_PATH_STYLE: ${{ vars.S3_FORCE_PATH_STYLE }}
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            export SCRIPT_DIR="/tmp"
            source /tmp/utils.sh
            export S3_ENABLED="${{ vars.S3_ENABLED }}"
            export S3_PROVIDER="${{ vars.S3_PROVIDER }}"
            export S3_ENDPOINT="${{ vars.S3_ENDPOINT }}"
            export S3_REGION="${{ vars.S3_REGION }}"
            export S3_BUCKET="${{ vars.S3_BUCKET }}"
            export S3_ACCESS_KEY_ID="${{ secrets.S3_ACCESS_KEY_ID }}"
            export S3_SECRET_ACCESS_KEY="${{ secrets.S3_SECRET_ACCESS_KEY }}"
            export S3_FORCE_PATH_STYLE="${{ vars.S3_FORCE_PATH_STYLE }}"
            chmod +x /tmp/restore.sh
            # Validate backup-id to prevent command injection
            BACKUP_ID="${{ needs.backup-infrastructure.outputs.backup-id }}"
            if [[ ! "$BACKUP_ID" =~ ^[a-zA-Z0-9_-]+$ ]]; then
              echo "ERROR: Invalid backup ID format"
              exit 1
            fi
            /tmp/restore.sh "$BACKUP_ID"
          ENDSSH

  # Verify Infrastructure
  verify-infrastructure:
    name: Verify Infrastructure
    runs-on: ubuntu-latest
    if: |
      always() &&
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main' && 
      (needs.recreate-infrastructure.result == 'success' || 
       needs.restore-backup.result == 'success' ||
       (needs.recreate-infrastructure.result == 'skipped' && needs.restore-backup.result == 'skipped'))
    environment: production
    needs: [recreate-infrastructure, restore-backup]
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Copy verify script
        run: |
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/docker-infra/verify.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/verify.sh
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/scripts/shared/utils.sh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/utils.sh

      - name: Verify infrastructure
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            export SCRIPT_DIR="/tmp"
            source /tmp/utils.sh
            chmod +x /tmp/verify.sh
            /tmp/verify.sh
          ENDSSH

  # Build Application (conditional)
  build-application:
    name: Build Application
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main' && 
      needs.detect-changes.outputs.app-changed == 'true'
    needs: [detect-changes, docker-build]
    timeout-minutes: 30
    steps:
      - name: Application build completed
        run: |
          echo "Application images already built in docker-build job"

  # Deploy to Production Server (Main Branch Only)
  deploy:
    name: Deploy to Production
    if: |
      always() &&
      github.event_name == 'push' && 
      github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment: production  # Use production environment secrets
    needs: [detect-changes, check-infrastructure, backup-infrastructure, debug-infrastructure, recreate-infrastructure, restore-backup, verify-infrastructure, build-application]
    concurrency:
      group: deploy-production
      cancel-in-progress: false
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Configure SSH
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known hosts
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -H ${{ secrets.SERVER_HOST }} >> ~/.ssh/known_hosts
          chmod 600 ~/.ssh/known_hosts

      - name: Create .env.production file
        run: |
          cat > /tmp/.env.production << EOF
          NODE_ENV=${{ vars.NODE_ENV }}
          IS_DEV=${{ vars.IS_DEV }}
          DATABASE_URL=${{ secrets.DATABASE_URL }}
          DIRECT_URL=${{ secrets.DIRECT_URL }}
          DATABASE_SQL_INJECTION_PREVENTION_ENABLED=${{ vars.DATABASE_SQL_INJECTION_PREVENTION_ENABLED }}
          DATABASE_ROW_LEVEL_SECURITY_ENABLED=${{ vars.DATABASE_ROW_LEVEL_SECURITY_ENABLED }}
          DATABASE_DATA_MASKING_ENABLED=${{ vars.DATABASE_DATA_MASKING_ENABLED }}
          DATABASE_RATE_LIMITING_ENABLED=${{ vars.DATABASE_RATE_LIMITING_ENABLED }}
          DATABASE_READ_REPLICAS_ENABLED=${{ vars.DATABASE_READ_REPLICAS_ENABLED }}
          DATABASE_READ_REPLICAS_STRATEGY=${{ vars.DATABASE_READ_REPLICAS_STRATEGY }}
          DATABASE_READ_REPLICAS_URLS=${{ vars.DATABASE_READ_REPLICAS_URLS }}
          CACHE_ENABLED=${{ vars.CACHE_ENABLED }}
          CACHE_PROVIDER=${{ vars.CACHE_PROVIDER }}
          DRAGONFLY_ENABLED=${{ vars.DRAGONFLY_ENABLED }}
          DRAGONFLY_HOST=${{ vars.DRAGONFLY_HOST }}
          DRAGONFLY_PORT=${{ vars.DRAGONFLY_PORT }}
          DRAGONFLY_KEY_PREFIX=${{ vars.DRAGONFLY_KEY_PREFIX }}
          DRAGONFLY_PASSWORD=${{ secrets.DRAGONFLY_PASSWORD }}
          REDIS_HOST=${{ vars.REDIS_HOST }}
          REDIS_PORT=${{ vars.REDIS_PORT }}
          REDIS_TTL=${{ vars.REDIS_TTL }}
          REDIS_PREFIX=${{ vars.REDIS_PREFIX }}
          REDIS_ENABLED=${{ vars.REDIS_ENABLED }}
          REDIS_PASSWORD=${{ vars.REDIS_PASSWORD }}
          PORT=${{ vars.PORT }}
          API_PREFIX=${{ vars.API_PREFIX }}
          HOST=${{ vars.HOST }}
          BIND_ADDRESS=${{ vars.BIND_ADDRESS }}
          BASE_URL=${{ vars.BASE_URL }}
          API_URL=${{ vars.API_URL }}
          FRONTEND_URL=${{ vars.FRONTEND_URL }}
          MAIN_DOMAIN=${{ vars.MAIN_DOMAIN }}
          API_DOMAIN=${{ vars.API_DOMAIN }}
          FRONTEND_DOMAIN=${{ vars.FRONTEND_DOMAIN }}
          JWT_SECRET=${{ secrets.JWT_SECRET }}
          JWT_EXPIRATION=${{ vars.JWT_EXPIRATION }}
          JWT_ACCESS_EXPIRES_IN=${{ vars.JWT_ACCESS_EXPIRES_IN }}
          JWT_REFRESH_EXPIRES_IN=${{ vars.JWT_REFRESH_EXPIRES_IN }}
          JWT_REFRESH_SECRET=${{ secrets.JWT_REFRESH_SECRET }}
          PRISMA_SCHEMA_PATH=${{ vars.PRISMA_SCHEMA_PATH }}
          LOG_LEVEL=${{ vars.LOG_LEVEL }}
          ENABLE_AUDIT_LOGS=${{ vars.ENABLE_AUDIT_LOGS }}
          RATE_LIMIT_ENABLED=${{ vars.RATE_LIMIT_ENABLED }}
          RATE_LIMIT_TTL=${{ vars.RATE_LIMIT_TTL }}
          RATE_LIMIT_MAX=${{ vars.RATE_LIMIT_MAX }}
          API_RATE_LIMIT=${{ vars.API_RATE_LIMIT }}
          AUTH_RATE_LIMIT=${{ vars.AUTH_RATE_LIMIT }}
          HEAVY_RATE_LIMIT=${{ vars.HEAVY_RATE_LIMIT }}
          USER_RATE_LIMIT=${{ vars.USER_RATE_LIMIT }}
          HEALTH_RATE_LIMIT=${{ vars.HEALTH_RATE_LIMIT }}
          MAX_AUTH_ATTEMPTS=${{ vars.MAX_AUTH_ATTEMPTS }}
          AUTH_ATTEMPT_WINDOW=${{ vars.AUTH_ATTEMPT_WINDOW }}
          MAX_CONCURRENT_SESSIONS=${{ vars.MAX_CONCURRENT_SESSIONS }}
          SESSION_INACTIVITY_THRESHOLD=${{ vars.SESSION_INACTIVITY_THRESHOLD }}
          SECURITY_RATE_LIMIT=${{ vars.SECURITY_RATE_LIMIT }}
          SECURITY_RATE_LIMIT_MAX=${{ vars.SECURITY_RATE_LIMIT_MAX }}
          SECURITY_RATE_LIMIT_WINDOW_MS=${{ vars.SECURITY_RATE_LIMIT_WINDOW_MS }}
          TRUST_PROXY=${{ vars.TRUST_PROXY }}
          EMAIL_PROVIDER=${{ vars.EMAIL_PROVIDER }}
          ZEPTOMAIL_ENABLED=${{ vars.ZEPTOMAIL_ENABLED }}
          ZEPTOMAIL_SEND_MAIL_TOKEN=${{ secrets.ZEPTOMAIL_SEND_MAIL_TOKEN }}
          ZEPTOMAIL_FROM_EMAIL=${{ vars.ZEPTOMAIL_FROM_EMAIL }}
          ZEPTOMAIL_FROM_NAME=${{ vars.ZEPTOMAIL_FROM_NAME }}
          ZEPTOMAIL_BOUNCE_ADDRESS=${{ vars.ZEPTOMAIL_BOUNCE_ADDRESS }}
          ZEPTOMAIL_API_BASE_URL=${{ vars.ZEPTOMAIL_API_BASE_URL }}
          
          # Clinic-Specific Email Configuration (Multi-Tenant)
          # ===================================================
          # ARCHITECTURE: Single Backend API, Multiple Frontends
          # - ONE backend API (API_URL) serves ALL clinics
          # - MULTIPLE frontends (one per clinic) connect to the SAME API
          # - Each frontend sends X-Clinic-ID header to identify which clinic it represents
          # - Only clinic-related credentials differ (email, WhatsApp, SMS, frontend URLs, etc.)
          # - All clinics share the same backend infrastructure (database, cache, services)
          #
          # Pattern: CLINIC_{SANITIZED_CLINIC_NAME}_{CONFIG_KEY}
          # Clinic names are sanitized: spaces/special chars ‚Üí underscores, uppercase
          # Example: "Vishwamurti Ayurvedelay" ‚Üí "VISHWAMURTI_AYURVEDELAY"
          #
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          # Example for "Aadesh Ayurvedalay":
          # CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_SEND_MAIL_TOKEN=${{ vars.CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_SEND_MAIL_TOKEN }}
          # CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_FROM_EMAIL=${{ vars.CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_FROM_EMAIL }}
          # CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_FROM_NAME=${{ vars.CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_FROM_NAME }}
          # CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_BOUNCE_ADDRESS=${{ vars.CLINIC_AADESH_AYURVEDELAY_ZEPTOMAIL_BOUNCE_ADDRESS }}
          #
          # Vishwamurti Ayurvedelay (CL0001)
          CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_SEND_MAIL_TOKEN=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_SEND_MAIL_TOKEN }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_FROM_EMAIL=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_FROM_EMAIL }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_FROM_NAME=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_FROM_NAME }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_BOUNCE_ADDRESS=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_ZEPTOMAIL_BOUNCE_ADDRESS }}
          
          # CORS Configuration - Single API, Multiple Frontends
          # =====================================================
          # IMPORTANT: Include ALL clinic frontend URLs in CORS_ORIGIN
          # Format: Comma-separated list (no spaces after commas)
          # Example: "https://ishswami.in,https://www.ishswami.in,https://vishwamurti.viddhakarma.com"
          # All frontends connect to the SAME backend API (API_URL)
          CORS_ORIGIN=${{ vars.CORS_ORIGIN }}
          CORS_CREDENTIALS=${{ vars.CORS_CREDENTIALS }}
          CORS_METHODS=${{ vars.CORS_METHODS }}
          SWAGGER_URL=${{ vars.SWAGGER_URL }}
          BULL_BOARD_URL=${{ vars.BULL_BOARD_URL }}
          SOCKET_URL=${{ secrets.SOCKET_URL }}
          PRISMA_STUDIO_URL=${{ vars.PRISMA_STUDIO_URL }}
          PGADMIN_URL=${{ vars.PGADMIN_URL }}
          WHATSAPP_ENABLED=${{ vars.WHATSAPP_ENABLED }}
          WHATSAPP_API_URL=${{ vars.WHATSAPP_API_URL }}
          WHATSAPP_API_KEY=${{ vars.WHATSAPP_API_KEY }}
          WHATSAPP_PHONE_NUMBER_ID=${{ vars.WHATSAPP_PHONE_NUMBER_ID }}
          WHATSAPP_BUSINESS_ACCOUNT_ID=${{ vars.WHATSAPP_BUSINESS_ACCOUNT_ID }}
          WHATSAPP_OTP_TEMPLATE_ID=${{ vars.WHATSAPP_OTP_TEMPLATE_ID }}
          WHATSAPP_APPOINTMENT_TEMPLATE_ID=${{ vars.WHATSAPP_APPOINTMENT_TEMPLATE_ID }}
          WHATSAPP_PRESCRIPTION_TEMPLATE_ID=${{ vars.WHATSAPP_PRESCRIPTION_TEMPLATE_ID }}
          
          # Clinic-Specific WhatsApp Configuration (Multi-Tenant)
          # =======================================================
          # Each clinic can have separate WhatsApp credentials
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          #
          # Vishwamurti Ayurvedelay (CL0001)
          CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_API_KEY=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_API_KEY }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_PHONE_NUMBER_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_PHONE_NUMBER_ID }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_BUSINESS_ACCOUNT_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_BUSINESS_ACCOUNT_ID }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_OTP_TEMPLATE_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_OTP_TEMPLATE_ID }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_APPOINTMENT_TEMPLATE_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_APPOINTMENT_TEMPLATE_ID }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_PRESCRIPTION_TEMPLATE_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_WHATSAPP_PRESCRIPTION_TEMPLATE_ID }}
          
          # Clinic-Specific Frontend URLs (Multi-Tenant)
          # ============================================
          # ARCHITECTURE: Single Backend API, Multiple Frontends
          # - Each clinic has its own frontend URL (e.g., https://vishwamurti.viddhakarma.com)
          # - All frontends connect to the SAME backend API (API_URL)
          # - Each frontend automatically sends X-Clinic-ID header in all requests
          # - Backend uses X-Clinic-ID to identify which clinic the request is for
          #
          # IMPORTANT: All clinic frontend URLs MUST be added to CORS_ORIGIN variable
          # Format: Comma-separated list (no spaces after commas)
          # Example: "https://ishswami.in,https://vishwamurti.viddhakarma.com,https://clinic2.viddhakarma.com"
          #
          # Pattern: CLINIC_{SANITIZED_CLINIC_NAME}_FRONTEND_URL
          # Example: "Vishwamurti Ayurvedelay" ‚Üí "VISHWAMURTI_AYURVEDELAY"
          #
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          # Example for "Aadesh Ayurvedalay":
          # CLINIC_AADESH_AYURVEDELAY_FRONTEND_URL=${{ vars.CLINIC_AADESH_AYURVEDELAY_FRONTEND_URL }}
          #
          # Vishwamurti Ayurvedelay (CL0001)
          CLINIC_VISHWAMURTI_AYURVEDELAY_FRONTEND_URL=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FRONTEND_URL }}
          
          VIDEO_ENABLED=${{ vars.VIDEO_ENABLED }}
          VIDEO_PROVIDER=${{ vars.VIDEO_PROVIDER }}
          OPENVIDU_URL=${{ vars.OPENVIDU_URL }}
          OPENVIDU_SECRET=${{ secrets.OPENVIDU_SECRET }}
          OPENVIDU_DOMAIN=${{ vars.OPENVIDU_DOMAIN }}
          OPENVIDU_WEBHOOK_ENABLED=${{ vars.OPENVIDU_WEBHOOK_ENABLED }}
          OPENVIDU_WEBHOOK_ENDPOINT=${{ vars.OPENVIDU_WEBHOOK_ENDPOINT }}
          OPENVIDU_WEBHOOK_EVENTS=${{ vars.OPENVIDU_WEBHOOK_EVENTS }}
          GOOGLE_CLIENT_ID=${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET=${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REDIRECT_URI=${{ vars.GOOGLE_REDIRECT_URI }}
          SESSION_SECRET=${{ secrets.SESSION_SECRET }}
          SESSION_TIMEOUT=${{ secrets.SESSION_TIMEOUT }}
          SESSION_SECURE_COOKIES=${{ vars.SESSION_SECURE_COOKIES }}
          SESSION_SAME_SITE=${{ vars.SESSION_SAME_SITE }}
          COOKIE_SECRET=${{ secrets.COOKIE_SECRET }}
          FIREBASE_PROJECT_ID=${{ vars.FIREBASE_PROJECT_ID }}
          FIREBASE_PRIVATE_KEY=${{ secrets.FIREBASE_PRIVATE_KEY }}
          FIREBASE_CLIENT_EMAIL=${{ vars.FIREBASE_CLIENT_EMAIL }}
          FIREBASE_DATABASE_URL=${{ vars.FIREBASE_DATABASE_URL }}
          FIREBASE_VAPID_KEY=${{ secrets.FIREBASE_VAPID_KEY }}
          
          # Clinic-Specific Firebase Configuration (Multi-Tenant)
          # ======================================================
          # Each clinic can have separate Firebase credentials for push notifications
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          #
          # Vishwamurti Ayurvedelay (CL0001)
          CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_PROJECT_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_PROJECT_ID }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_PRIVATE_KEY=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_PRIVATE_KEY }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_CLIENT_EMAIL=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_CLIENT_EMAIL }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_DATABASE_URL=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_DATABASE_URL }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_VAPID_KEY=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FIREBASE_VAPID_KEY }}
          
          # Clinic-Specific SMS Configuration (Multi-Tenant)
          # ================================================
          # Each clinic can have separate SMS provider credentials
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          #
          # Vishwamurti Ayurvedelay (CL0001)
          CLINIC_VISHWAMURTI_AYURVEDELAY_SMS_API_KEY=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_SMS_API_KEY }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_SMS_API_SECRET=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_SMS_API_SECRET }}
          CLINIC_VISHWAMURTI_AYURVEDELAY_SMS_FROM_NUMBER=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_SMS_FROM_NUMBER }}
          
          # Clinic-Specific OpenVidu Configuration (Multi-Tenant)
          # ====================================================
          # Each clinic can have separate OpenVidu video server configuration
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_OPENVIDU_URL=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_OPENVIDU_URL }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_OPENVIDU_SECRET=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_OPENVIDU_SECRET }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_OPENVIDU_DOMAIN=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_OPENVIDU_DOMAIN }}
          
          # Clinic-Specific S3 Storage Configuration (Multi-Tenant)
          # =======================================================
          # Each clinic can have separate S3 storage bucket and credentials
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_S3_BUCKET=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_S3_BUCKET }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_S3_ACCESS_KEY_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_S3_ACCESS_KEY_ID }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_S3_SECRET_ACCESS_KEY=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_S3_SECRET_ACCESS_KEY }}
          
          # Clinic-Specific Social Auth Configuration (Multi-Tenant)
          # ========================================================
          # Each clinic can have separate OAuth credentials (Google, Facebook, Apple)
          # To add more clinics, duplicate the pattern below with the clinic's sanitized name
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_GOOGLE_CLIENT_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_GOOGLE_CLIENT_ID }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_GOOGLE_CLIENT_SECRET=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_GOOGLE_CLIENT_SECRET }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_FACEBOOK_APP_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FACEBOOK_APP_ID }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_FACEBOOK_APP_SECRET=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_FACEBOOK_APP_SECRET }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_APPLE_CLIENT_ID=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_APPLE_CLIENT_ID }}
          # Example: CLINIC_VISHWAMURTI_AYURVEDELAY_APPLE_CLIENT_SECRET=${{ vars.CLINIC_VISHWAMURTI_AYURVEDELAY_APPLE_CLIENT_SECRET }}
          
          FACEBOOK_APP_ID=${{ vars.FACEBOOK_APP_ID }}
          FACEBOOK_APP_SECRET=${{ vars.FACEBOOK_APP_SECRET }}
          APPLE_CLIENT_ID=${{ vars.APPLE_CLIENT_ID }}
          APPLE_CLIENT_SECRET=${{ vars.APPLE_CLIENT_SECRET }}
          S3_ENABLED=${{ vars.S3_ENABLED }}
          S3_PROVIDER=${{ vars.S3_PROVIDER }}
          S3_ENDPOINT=${{ vars.S3_ENDPOINT }}
          S3_REGION=${{ vars.S3_REGION }}
          S3_BUCKET=${{ vars.S3_BUCKET }}
          S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY }}
          S3_FORCE_PATH_STYLE=${{ vars.S3_FORCE_PATH_STYLE }}
          S3_PUBLIC_URL_EXPIRATION=${{ vars.S3_PUBLIC_URL_EXPIRATION }}
          CDN_URL=${{ vars.CDN_URL }}
          DOCKER_ENV=${{ vars.DOCKER_ENV }}
          DOCKER_NETWORK=${{ vars.DOCKER_NETWORK }}
          EOF

      - name: Copy files to server
        run: |
          # Copy all deployment scripts
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts -r devops/scripts/shared devops/scripts/docker-infra ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/opt/healthcare-backend/devops/scripts/
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts /tmp/.env.production ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/.env.production
          # Copy docker-compose file
          scp -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts devops/docker/docker-compose.prod.yml ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }}:/tmp/docker-compose.prod.yml

      - name: Set deployment image name
        id: deploy-image
        run: |
          REPO_LOWER=$(echo "${{ env.IMAGE_REPO }}" | tr '[:upper:]' '[:lower:]')
          IMAGE_FULL="ghcr.io/${REPO_LOWER}/${{ env.IMAGE_NAME }}"
          echo "image=${IMAGE_FULL}" >> $GITHUB_OUTPUT
          echo "Image: ${IMAGE_FULL}"

      - name: Setup server directories
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            set -e
            
            # Run directory setup script
            if [[ -f /opt/healthcare-backend/devops/scripts/docker-infra/setup-directories.sh ]]; then
              echo "Setting up server directories..."
              chmod +x /opt/healthcare-backend/devops/scripts/docker-infra/setup-directories.sh
              /opt/healthcare-backend/devops/scripts/docker-infra/setup-directories.sh
            else
              echo "Setup script not found, creating directories manually..."
              mkdir -p /opt/healthcare-backend/backups/{postgres,dragonfly,metadata}
              mkdir -p /opt/healthcare-backend/data/{postgres,dragonfly,openvidu_recordings}
              # /var/log/deployments requires sudo if not running as root
              if [[ "$EUID" -eq 0 ]]; then
                mkdir -p /var/log/deployments
                chmod 755 /var/log/deployments
              else
                sudo mkdir -p /var/log/deployments
                sudo chmod 755 /var/log/deployments
              fi
              chmod 700 /opt/healthcare-backend/backups
              chmod 755 /opt/healthcare-backend/data
              echo "Directories created"
            fi
          ENDSSH

      - name: Deploy to server via SSH
        env:
          SERVER_DEPLOY_PATH: ${{ vars.SERVER_DEPLOY_PATH }}
          IMAGE_TAG: main-${{ github.sha }}
          REGISTRY: ${{ env.REGISTRY }}
          IMAGE: ${{ steps.deploy-image.outputs.image }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_USERNAME: ${{ github.actor }}
        run: |
          ssh -o StrictHostKeyChecking=accept-new -o UserKnownHostsFile=~/.ssh/known_hosts ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} << 'ENDSSH'
            set -e
            
            # Set deployment variables (values embedded from GitHub Actions)
            # Handle SERVER_DEPLOY_PATH with default value and input validation
            # Security: Validate SERVER_DEPLOY_PATH to prevent path traversal attacks
            SERVER_DEPLOY_PATH_SECRET_VALUE="${{ vars.SERVER_DEPLOY_PATH }}"
            
            # Input validation: Only allow alphanumeric, forward slashes, hyphens, and underscores
            # Prevent path traversal and command injection
            if [ -n "${SERVER_DEPLOY_PATH_SECRET_VALUE}" ] && [ "${SERVER_DEPLOY_PATH_SECRET_VALUE}" != "" ]; then
              # Validate path format (no .., no spaces, no special chars except /, -, _)
              if [[ ! "${SERVER_DEPLOY_PATH_SECRET_VALUE}" =~ ^[a-zA-Z0-9/_-]+$ ]] || [[ "${SERVER_DEPLOY_PATH_SECRET_VALUE}" == *".."* ]]; then
                echo "‚ùå ERROR: Invalid SERVER_DEPLOY_PATH format (security check failed)"
                exit 1
              fi
              export SERVER_DEPLOY_PATH="${SERVER_DEPLOY_PATH_SECRET_VALUE}"
              echo "‚úÖ Using SERVER_DEPLOY_PATH from secret: '${SERVER_DEPLOY_PATH}'"
            else
              export SERVER_DEPLOY_PATH="/opt/healthcare-backend"
              echo "‚úÖ Using default SERVER_DEPLOY_PATH: '${SERVER_DEPLOY_PATH}'"
            fi
            
            # Final safety check - should never be empty at this point
            if [ -z "${SERVER_DEPLOY_PATH}" ] || [ "${SERVER_DEPLOY_PATH}" = "" ]; then
              echo "‚ùå ERROR: SERVER_DEPLOY_PATH is empty! Forcing to default..."
              export SERVER_DEPLOY_PATH="/opt/healthcare-backend"
            fi
            
            # One final verification
            if [ -z "${SERVER_DEPLOY_PATH}" ]; then
              echo "‚ùå FATAL: SERVER_DEPLOY_PATH is still empty after all attempts!"
              exit 1
            fi
            
            # Security: Don't log full path in production logs (masked by GitHub Actions)
            echo "üìÅ Final SERVER_DEPLOY_PATH='[REDACTED]'"
            export IMAGE_TAG="main-${{ github.sha }}"
            export REGISTRY="${{ env.REGISTRY }}"
            export IMAGE="${{ steps.deploy-image.outputs.image }}"
            export GITHUB_TOKEN="${{ secrets.GITHUB_TOKEN }}"
            export GITHUB_USERNAME="${{ github.actor }}"
            
            # Debug: Show deployment info (secrets masked by GitHub Actions)
            echo "Deploying image: ${IMAGE}:${IMAGE_TAG}"
            # Security: Don't log full path in production logs
            echo "Server deployment path: [REDACTED]"
            
            # Validate IMAGE is set
            if [ -z "${IMAGE}" ] || [ "${IMAGE}" = "ghcr.io/your-username/your-repo/healthcare-api" ]; then
              echo "ERROR: IMAGE environment variable is not set or invalid"
              echo "IMAGE value: '${IMAGE}'"
              exit 1
            fi
            
            # Validate SERVER_DEPLOY_PATH is set (should never be empty after our check above)
            if [ -z "${SERVER_DEPLOY_PATH}" ]; then
              echo "‚ùå ERROR: SERVER_DEPLOY_PATH is empty after default assignment!"
              echo "This should never happen. Check the logic above."
              exit 1
            fi
            
            # Create deployment directory if it doesn't exist (deploy.sh expects this)
            # Use SERVER_DEPLOY_PATH directly - no intermediate variable needed
            # Verify it's still set before using it
            if [ -z "${SERVER_DEPLOY_PATH}" ]; then
              echo "‚ùå ERROR: SERVER_DEPLOY_PATH is empty when trying to create directory!"
              exit 1
            fi
            
            echo "üìÅ Creating deployment directory: ${SERVER_DEPLOY_PATH}"
            mkdir -p "${SERVER_DEPLOY_PATH}/devops/docker" || {
              echo "‚ùå ERROR: Failed to create directory: ${SERVER_DEPLOY_PATH}/devops/docker"
              exit 1
            }
            
            echo "üìÑ Moving .env.production to ${SERVER_DEPLOY_PATH}/.env.production"
            mv /tmp/.env.production "${SERVER_DEPLOY_PATH}/.env.production" || {
              echo "‚ùå ERROR: Failed to move .env.production to ${SERVER_DEPLOY_PATH}/.env.production"
              exit 1
            }
            chmod 600 "${SERVER_DEPLOY_PATH}/.env.production"
            
            echo "üìÑ Moving docker-compose.prod.yml to ${SERVER_DEPLOY_PATH}/devops/docker/docker-compose.prod.yml"
            mv /tmp/docker-compose.prod.yml "${SERVER_DEPLOY_PATH}/devops/docker/docker-compose.prod.yml" || {
              echo "‚ùå ERROR: Failed to move docker-compose.prod.yml"
              exit 1
            }
            
            # Make scripts executable
            chmod +x /opt/healthcare-backend/devops/scripts/docker-infra/*.sh
            chmod +x /opt/healthcare-backend/devops/scripts/shared/*.sh
            
            # Set deployment variables for deploy.sh
            export INFRA_CHANGED="${{ needs.detect-changes.outputs.infra-changed }}"
            export APP_CHANGED="${{ needs.detect-changes.outputs.app-changed }}"
            export INFRA_HEALTHY="${{ needs.check-infrastructure.outputs.infra-healthy }}"
            export INFRA_STATUS="${{ needs.check-infrastructure.outputs.infra-status }}"
            export BACKUP_ID="${{ needs.backup-infrastructure.outputs.backup-id || '' }}"
            
            # Flag to indicate infrastructure operations were already handled by CI/CD jobs
            # This prevents deploy.sh from duplicating backup/recreate/restore operations
            if [[ "${{ needs.detect-changes.outputs.infra-changed }}" == "true" ]] || \
               [[ "${{ needs.check-infrastructure.outputs.infra-healthy }}" == "false" ]]; then
              export INFRA_ALREADY_HANDLED="true"
            else
              export INFRA_ALREADY_HANDLED="false"
            fi
            
            # Run smart deployment orchestrator
            # Note: deploy.sh will skip infrastructure operations if INFRA_ALREADY_HANDLED=true
            # and only handle application deployment
            cd /opt/healthcare-backend
            /opt/healthcare-backend/devops/scripts/docker-infra/deploy.sh
            
          ENDSSH

      - name: Verify deployment
        if: always()
        run: |
          echo "üè• Verifying deployment health..."
          sleep 15  # Wait for services to fully start
          
          MAX_RETRIES=10
          RETRY_COUNT=0
          HEALTH_URL="https://api.ishswami.in/health"
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if curl -f -s "${HEALTH_URL}" > /dev/null 2>&1; then
              echo "‚úÖ Deployment health check passed!"
              exit 0
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "‚è≥ Waiting for health check... (${RETRY_COUNT}/${MAX_RETRIES})"
            sleep 5
          done
          
          echo "‚ùå Health check failed after ${MAX_RETRIES} attempts"
          echo "üîÑ Rollback should have been triggered automatically by deploy script"
          exit 1

      - name: Deployment Success
        run: |
          echo "‚úÖ Deployment completed successfully!"
          echo "Image: ${{ steps.deploy-image.outputs.image }}:main-${{ github.sha }}"
          # Security: Don't log server hostname in public logs
          echo "Server: [REDACTED]"

  # Summary Report
  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [lint, security, docker-build, deploy]
    if: always() && !contains(needs.*.result, 'failure')
    steps:
      - name: Report Success
        run: |
          echo "‚úÖ All CI checks passed successfully!"
          if [ "${{ github.ref }}" == "refs/heads/main" ] && [ "${{ github.event_name }}" == "push" ]; then
            echo "üöÄ Deployment to production completed!"
          else
            echo "Ready for merge to main branch"
          fi
