services:
  api:
    build:
      context: ../..
      dockerfile: devops/docker/Dockerfile
      target: production
      args:
        - BUILDKIT_INLINE_CACHE=1
      cache_from:
        - type=registry,ref=node:20-slim
    container_name: latest-api
    hostname: api
    ports:
      - "${API_PORT:-8088}:${API_PORT:-8088}"
    env_file:
      - ../../.env.production
    volumes:
      - ./logs:/app/logs
      - /etc/letsencrypt:/etc/letsencrypt:ro
    environment:
      NODE_ENV: production
      DEV_MODE: "false"
      DOCKER_ENV: "true"
      CORS_ORIGIN: "https://ishswami.in,https://www.ishswami.in"
      FRONTEND_URL: https://ishswami.in
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      # Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users, ~1200-1800 req/s (104M-156M requests/day)
      # Can run on 6 vCPU/12GB RAM initially (Docker will enforce limits)
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/userdb?connection_limit=60&pool_timeout=60&statement_timeout=60000&idle_in_transaction_session_timeout=60000&connect_timeout=60&pool_size=30&max_connections=60
      # Cache Provider Configuration (Dragonfly is the only cache provider in production)
      CACHE_PROVIDER: dragonfly
      
      # Dragonfly Configuration (primary cache provider)
      DRAGONFLY_ENABLED: "true"
      DRAGONFLY_HOST: dragonfly
      DRAGONFLY_PORT: 6379
      DRAGONFLY_KEY_PREFIX: "healthcare:"
      
      TRUST_PROXY: 1
      PRISMA_SCHEMA_PATH: /app/src/libs/infrastructure/database/prisma/schema.prisma
      HOST: 0.0.0.0
      PORT: ${API_PORT:-8088}
      BIND_ADDRESS: 0.0.0.0
      SOCKET_HOST: 0.0.0.0
      SOCKET_PORT: ${API_PORT:-8088}
      NPM_CONFIG_LOGLEVEL: error
      API_URL: https://api.ishswami.in
      SWAGGER_URL: /docs
      BULL_BOARD_URL: /queue-dashboard
      SOCKET_URL: /socket.io
      LOGGER_URL: /logger
      BASE_URL: https://api.ishswami.in
      API_PREFIX: /api/v1
      MAIN_DOMAIN: ishswami.in
      API_DOMAIN: api.ishswami.in
      FRONTEND_DOMAIN: ishswami.in
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-key-change-in-production}
      JWT_EXPIRATION: 24h
      
      # Session Configuration (Fastify Session with CacheService/Dragonfly)
      SESSION_SECRET: ${SESSION_SECRET:-your-session-secret-change-in-production-min-32-chars-long}
      SESSION_TIMEOUT: ${SESSION_TIMEOUT:-86400}
      SESSION_SECURE_COOKIES: ${SESSION_SECURE_COOKIES:-true}
      SESSION_SAME_SITE: ${SESSION_SAME_SITE:-strict}
      COOKIE_SECRET: ${COOKIE_SECRET:-your-cookie-secret-change-in-production-min-32-chars}
      
      LOG_LEVEL: info
      ENABLE_AUDIT_LOGS: "true"
      SECURITY_RATE_LIMIT: "true"
      # Optimized for 8 vCPU/24GB RAM: ~1200-1800 req/s peak capacity (700-900 concurrent users)
      SECURITY_RATE_LIMIT_MAX: 4000
      SECURITY_RATE_LIMIT_WINDOW_MS: 1000
      # Cache TTL and prefix (used by Dragonfly)
      CACHE_TTL: 3600
      CACHE_PREFIX: "healthcare:"
      # Rate limiting: Allow 600 req/min per IP (supports 800 users * 5 req/day + bursts)
      RATE_LIMIT_TTL: 60
      RATE_LIMIT_MAX: 600
      API_RATE_LIMIT: 1000
      AUTH_RATE_LIMIT: 30
      HEAVY_RATE_LIMIT: 50
      USER_RATE_LIMIT: 500
      HEALTH_RATE_LIMIT: 2000
    expose:
      - "${API_PORT:-8088}"
    networks:
      app-network:
        ipv4_address: 172.18.0.5
        aliases:
          - api.ishswami.in
    dns: []
    extra_hosts:
      - "api:172.18.0.5"
      - "postgres:172.18.0.2"
      - "dragonfly:172.18.0.4"
    depends_on:
      postgres:
        condition: service_healthy
      dragonfly:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:${API_PORT:-8088}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        # Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users, ~1200-1800 req/s
        # Can run on 6 vCPU/12GB RAM initially (Docker enforces limits)
        limits:
          cpus: "3.0"      # Target: 8 vCPU server (3 CPU for API)
          memory: 6G       # Target: 24GB server (6GB for API)
        reservations:
          cpus: "1.5"      # Minimum guaranteed (works on 6 vCPU server)
          memory: 2G       # Minimum guaranteed (works on 12GB server)
    command: >
      sh -c "
        pnpm exec prisma generate --schema=/app/src/libs/infrastructure/database/prisma/schema.prisma &&
        pnpm exec prisma migrate deploy --schema=/app/src/libs/infrastructure/database/prisma/schema.prisma &&
        node dist/main.js
      "
    labels:
      - "com.docker.compose.service=api"
      - "app.component=backend"
      - "app.type=api"

  postgres:
    image: postgres:16-alpine
    container_name: latest-postgres
    hostname: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data/pgdata
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: userdb
      # Optimized for 8 vCPU/24GB RAM: API (60) + Worker (30) + overhead = 120
      POSTGRES_MAX_CONNECTIONS: 120
      POSTGRES_SHARED_BUFFERS: 2GB
      PGDATA: /var/lib/postgresql/data/pgdata
    networks:
      app-network:
        ipv4_address: 172.18.0.2
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d userdb"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        # Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users
        # Can run on 6 vCPU/12GB RAM initially (Docker enforces limits)
        limits:
          cpus: "3.0"      # Target: 8 vCPU server (3 CPU for PostgreSQL)
          memory: 10G      # Target: 24GB server (10GB for PostgreSQL)
        reservations:
          cpus: "1.5"      # Minimum guaranteed (works on 6 vCPU server)
          memory: 3G       # Minimum guaranteed (works on 12GB server)
    restart: unless-stopped
    shm_size: 256mb  # Shared memory for PostgreSQL
    stop_grace_period: 1m
    command: >
      postgres 
      -c max_connections=120 
      -c shared_buffers=2GB 
      -c effective_cache_size=12GB 
      -c maintenance_work_mem=256MB 
      -c checkpoint_completion_target=0.9 
      -c wal_buffers=32MB 
      -c default_statistics_target=100 
      -c random_page_cost=1.1 
      -c effective_io_concurrency=200 
      -c work_mem=16MB 
      -c min_wal_size=2GB 
      -c max_wal_size=8GB 
      -c max_worker_processes=8 
      -c max_parallel_workers_per_gather=4 
      -c max_parallel_workers=8 
      -c max_parallel_maintenance_workers=4 
      -c idle_in_transaction_session_timeout=60000 
      -c statement_timeout=60000 
      -c lock_timeout=60000 
      -c listen_addresses='*' 
      -c log_connections=on 
      -c log_disconnections=on 
      -c tcp_keepalives_idle=60 
      -c tcp_keepalives_interval=10 
      -c tcp_keepalives_count=3 
      -c client_min_messages=warning
    labels:
      - "com.docker.compose.service=postgres"
      - "app.component=database"
      - "app.type=postgres"
      - "app.healthcheck=enabled"
      - "app.persist=true"

  dragonfly:
    image: docker.dragonflydb.io/dragonflydb/dragonfly:latest
    container_name: latest-dragonfly
    hostname: dragonfly
    command: >
      --alsologtostderr
      --cache_mode=false
      --maxmemory=4gb
      --proactor_threads=6
      --logtostderr
      --default_lua_flags=allow-undeclared-keys
    ports:
      - "6380:6379"
    volumes:
      - dragonfly_data:/data
    networks:
      app-network:
        ipv4_address: 172.18.0.4
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -p 6379 ping || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        # Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users
        # Can run on 6 vCPU/12GB RAM initially (Docker enforces limits)
        limits:
          cpus: "1.5"      # Target: 8 vCPU server (1.5 CPU for Dragonfly)
          memory: 4G       # Target: 24GB server (4GB for Dragonfly cache)
        reservations:
          cpus: "0.5"      # Minimum guaranteed (works on 6 vCPU server)
          memory: 1G       # Minimum guaranteed (works on 12GB server)
    restart: unless-stopped
    sysctls:
      net.core.somaxconn: 2048  # Increased from 1024 for more connections
    ulimits:
      nproc: 65535
      nofile:
        soft: 65535
        hard: 65535
    labels:
      - "com.docker.compose.service=dragonfly"
      - "app.component=cache"
      - "app.type=dragonfly"
      - "app.healthcheck=enabled"

  worker:
    build:
      context: ../..
      dockerfile: devops/docker/Dockerfile
      target: production
      args:
        - BUILDKIT_INLINE_CACHE=1
      cache_from:
        - type=registry,ref=node:20-slim
    container_name: latest-worker
    hostname: worker
    env_file:
      - ../../.env.production
    environment:
      NODE_ENV: production
      APP_MODE: worker
      SERVICE_NAME: worker
      DEV_MODE: "false"
      DOCKER_ENV: "true"
      
      # Database Configuration - Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/userdb?connection_limit=30&pool_timeout=60&statement_timeout=60000&idle_in_transaction_session_timeout=60000&connect_timeout=60&pool_size=15&max_connections=30
      PRISMA_SCHEMA_PATH: /app/src/libs/infrastructure/database/prisma/schema.prisma
      
      # Cache Provider Configuration (Dragonfly is the only cache provider in production)
      CACHE_PROVIDER: dragonfly
      CACHE_ENABLED: "true"
      DRAGONFLY_ENABLED: "true"
      DRAGONFLY_HOST: dragonfly
      DRAGONFLY_PORT: 6379
      DRAGONFLY_KEY_PREFIX: "healthcare:"
      
      # JWT Configuration (for queue operations)
      JWT_SECRET: ${JWT_SECRET:-your-super-secret-key-change-in-production}
      
      # BullMQ Worker Configuration - Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users
      BULL_WORKER_CONCURRENCY: "10"
      BULL_MAX_JOBS_PER_WORKER: "100"
      
      # Logging Configuration
      LOG_LEVEL: info
      ENABLE_AUDIT_LOGS: "true"
      
      # Email Configuration (for queue jobs)
      AWS_REGION: ${AWS_REGION:-}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      
      # Firebase Configuration (for notifications)
      FIREBASE_PROJECT_ID: ${FIREBASE_PROJECT_ID:-}
      FIREBASE_PRIVATE_KEY: ${FIREBASE_PRIVATE_KEY:-}
      FIREBASE_CLIENT_EMAIL: ${FIREBASE_CLIENT_EMAIL:-}
    volumes:
      - ./logs:/app/logs
    networks:
      app-network:
        ipv4_address: 172.18.0.6
        aliases:
          - worker.ishswami.in
    dns: []
    extra_hosts:
      - "worker:172.18.0.6"
      - "postgres:172.18.0.2"
      - "dragonfly:172.18.0.4"
    depends_on:
      postgres:
        condition: service_healthy
      dragonfly:
        condition: service_healthy
      api:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "-e", "process.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        # Optimized for 8 vCPU/24GB RAM: 700-900 concurrent users
        # Can run on 6 vCPU/12GB RAM initially (Docker enforces limits)
        limits:
          cpus: "1.0"      # Target: 8 vCPU server (1 CPU for Worker)
          memory: 2G        # Target: 24GB server (2GB for Worker)
        reservations:
          cpus: "0.5"       # Minimum guaranteed (works on 6 vCPU server)
          memory: 512M      # Minimum guaranteed (works on 12GB server)
    command: >
      sh -c "
        pnpm exec prisma generate --schema=/app/src/libs/infrastructure/database/prisma/schema.prisma &&
        node dist/worker-bootstrap.js
      "
    labels:
      - "com.docker.compose.service=worker"
      - "app.component=worker"
      - "app.type=worker"

volumes:
  postgres_data:
    name: latest_postgres_data
  dragonfly_data:
    name: latest_dragonfly_data

networks:
  app-network:
    name: app-network
    ipam:
      config:
        - subnet: 172.18.0.0/16

