apiVersion: v1
kind: ConfigMap
metadata:
  name: healthcare-api-config
  namespace: healthcare-backend
  labels:
    app: healthcare
    component: config
data:
  # Application Environment
  NODE_ENV: "production"
  PORT: "8088"
  IS_DEV: "false"

  # Database Configuration
  DB_POOL_MIN: "10"
  DB_POOL_MAX: "100"
  DB_CONNECTION_TIMEOUT: "30000"
  DB_IDLE_TIMEOUT: "600000"

  # Cache Provider Configuration (Dragonfly is default)
  CACHE_PROVIDER: "dragonfly"
  
  # Redis Configuration (for Redis provider)
  REDIS_HOST: "redis"
  REDIS_PORT: "6379"
  REDIS_TTL: "3600"
  REDIS_PREFIX: "healthcare:"
  REDIS_MAX_MEMORY: "2gb"
  REDIS_POLICY: "allkeys-lru"
  
  # Dragonfly Configuration (Primary Cache Provider - default provider - 26x faster than Redis)
  DRAGONFLY_ENABLED: "true"
  DRAGONFLY_HOST: "dragonfly"
  DRAGONFLY_PORT: "6379"
  DRAGONFLY_KEY_PREFIX: "healthcare:"

  # JWT Configuration
  JWT_EXPIRATION: "24h"
  JWT_REFRESH_EXPIRATION: "7d"
  
  # Session Configuration (Fastify Session with CacheService/Dragonfly)
  SESSION_TIMEOUT: "86400"
  SESSION_SECURE_COOKIES: "true"
  SESSION_SAME_SITE: "strict"

  # Rate Limiting
  RATE_LIMIT_MAX: "1000"
  RATE_LIMIT_WINDOW: "1 minute"

  # CORS Configuration
  CORS_ORIGIN: "https://ishswami.in,https://www.ishswami.in,https://api.ishswami.in,https://video.ishswami.in,https://meet.ishswami.in"

  # Frontend URLs
  FRONTEND_URL: "https://ishswami.in"
  API_URL: "https://api.ishswami.in"

  # API Configuration
  SWAGGER_URL: "/docs"
  BULL_BOARD_URL: "/queue-dashboard"
  SOCKET_URL: "/socket.io"
  LOGGER_URL: "/logger"

  # WebSocket Configuration
  WS_PING_TIMEOUT: "60000"
  WS_PING_INTERVAL: "25000"
  WS_MAX_HTTP_BUFFER_SIZE: "1000000"

  # Clustering Configuration
  CLUSTER_MODE: "horizontal"
  ENABLE_CLUSTERING: "false"  # Use K8s horizontal scaling instead

  # Logging Configuration
  LOG_LEVEL: "info"
  LOG_FORMAT: "json"
  LOG_MAX_FILES: "30d"
  LOG_MAX_SIZE: "100m"

  # Health Check
  HEALTH_CHECK_TIMEOUT: "5000"
  HEALTH_CHECK_INTERVAL: "30000"

  # Performance
  MAX_CONNECTIONS: "1000"
  KEEP_ALIVE_TIMEOUT: "65000"
  CONNECTION_TIMEOUT: "60000"
  REQUEST_TIMEOUT: "30000"

  # Feature Flags
  ENABLE_SWAGGER: "true"
  ENABLE_BULL_BOARD: "true"
  ENABLE_METRICS: "true"
  ENABLE_TRACING: "true"
  ENABLE_DEBUG: "false"

  # Email Configuration
  AWS_SES_FROM_EMAIL: "noreply@ishswami.in"
  AWS_SES_FROM_NAME: "Healthcare App"

  # Video Consultation (Dual Provider: OpenVidu primary, Jitsi fallback)
  # NOTE: These values are updated dynamically by configuration scripts
  # OpenVidu (Primary - like Dragonfly in cache pattern)
  # Jitsi (Fallback - like Redis in cache pattern)
  VIDEO_ENABLED: "true"
  VIDEO_PROVIDER: "openvidu"
  
  # OpenVidu Configuration (Primary Video Provider)
  OPENVIDU_ENABLED: "true"
  OPENVIDU_URL: "https://video.ishswami.in"
  OPENVIDU_DOMAIN: "video.ishswami.in"
  # OpenVidu Webhook Configuration (Optimized Architecture: Webhooks → Backend → Socket.IO)
  # Enable webhooks to reduce Socket.IO load for video events
  OPENVIDU_WEBHOOK_ENABLED: "false"
  OPENVIDU_WEBHOOK_ENDPOINT: "https://api.ishswami.in/api/v1/webhooks/openvidu"
  OPENVIDU_WEBHOOK_EVENTS: "sessionCreated,sessionDestroyed,participantJoined,participantLeft,recordingStarted,recordingStopped"
  
  # Jitsi Configuration (Fallback)
  JITSI_DOMAIN: "meet.ishswami.in"
  JITSI_BASE_DOMAIN: "ishswami.in"
  JITSI_SUBDOMAIN: "meet"
  JITSI_APP_ID: "healthcare-jitsi-app"
  JITSI_ENABLE_RECORDING: "true"
  JITSI_ENABLE_WAITING_ROOM: "true"
  JITSI_BASE_URL: "https://meet.ishswami.in"
  JITSI_WS_URL: "wss://meet.ishswami.in/xmpp-websocket"
  
  # Google OAuth Configuration
  GOOGLE_CLIENT_ID: ""
  GOOGLE_CLIENT_SECRET: ""
  GOOGLE_REDIRECT_URI: "https://api.ishswami.in/auth/google/callback"

  # Notification Configuration
  ENABLE_PUSH_NOTIFICATIONS: "true"
  ENABLE_EMAIL_NOTIFICATIONS: "true"
  ENABLE_SMS_NOTIFICATIONS: "false"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: healthcare-worker-config
  namespace: healthcare-backend
  labels:
    app: healthcare
    component: worker
data:
  # Worker Configuration
  NODE_ENV: "production"
  APP_MODE: "worker"

  # BullMQ Configuration
  BULL_WORKER_CONCURRENCY: "5"
  BULL_MAX_JOBS_PER_WORKER: "100"
  BULL_REMOVE_ON_COMPLETE: "100"
  BULL_REMOVE_ON_FAIL: "1000"
  BULL_LOCK_DURATION: "30000"
  BULL_LOCK_RENEW_TIME: "15000"
  BULL_STALLED_INTERVAL: "30000"
  BULL_MAX_STALLED_COUNT: "3"

  # Queue Names
  QUEUE_NOTIFICATIONS: "notifications"
  QUEUE_EMAILS: "emails"
  QUEUE_APPOINTMENTS: "appointments"
  QUEUE_REMINDERS: "reminders"
  QUEUE_ANALYTICS: "analytics"
  QUEUE_REPORTS: "reports"

  # Cache Provider Configuration (Dragonfly is default)
  CACHE_PROVIDER: "dragonfly"
  
  # Redis Configuration (for Redis provider)
  REDIS_HOST: "redis"
  REDIS_PORT: "6379"
  REDIS_PREFIX: "healthcare:queue:"
  
  # Dragonfly Configuration (default provider)
  DRAGONFLY_ENABLED: "true"
  DRAGONFLY_HOST: "dragonfly"
  DRAGONFLY_PORT: "6379"
  DRAGONFLY_KEY_PREFIX: "healthcare:queue:"

  # Database Configuration
  DB_POOL_MIN: "5"
  DB_POOL_MAX: "20"

  # Logging
  LOG_LEVEL: "info"
  LOG_FORMAT: "json"

  # Email Service
  EMAIL_RETRY_ATTEMPTS: "3"
  EMAIL_RETRY_DELAY: "5000"
  EMAIL_BATCH_SIZE: "50"

  # Notification Service
  NOTIFICATION_RETRY_ATTEMPTS: "3"
  NOTIFICATION_BATCH_SIZE: "100"

  # Performance
  WORKER_GRACEFUL_SHUTDOWN_TIMEOUT: "30000"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-init-scripts
  namespace: healthcare-backend
  labels:
    app: postgres
    component: database
data:
  01-init-extensions.sql: |
    -- Create extensions for PostgreSQL optimization
    CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
    CREATE EXTENSION IF NOT EXISTS pg_trgm;
    CREATE EXTENSION IF NOT EXISTS btree_gin;
    CREATE EXTENSION IF NOT EXISTS btree_gist;
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

  02-optimize-settings.sql: |
    -- Optimize PostgreSQL for production
    ALTER SYSTEM SET shared_buffers = '2GB';
    ALTER SYSTEM SET effective_cache_size = '6GB';
    ALTER SYSTEM SET maintenance_work_mem = '512MB';
    ALTER SYSTEM SET checkpoint_completion_target = 0.9;
    ALTER SYSTEM SET wal_buffers = '16MB';
    ALTER SYSTEM SET default_statistics_target = 100;
    ALTER SYSTEM SET random_page_cost = 1.1;
    ALTER SYSTEM SET effective_io_concurrency = 200;
    ALTER SYSTEM SET work_mem = '16MB';
    ALTER SYSTEM SET min_wal_size = '1GB';
    ALTER SYSTEM SET max_wal_size = '4GB';
    ALTER SYSTEM SET max_worker_processes = 8;
    ALTER SYSTEM SET max_parallel_workers_per_gather = 4;
    ALTER SYSTEM SET max_parallel_workers = 8;
    ALTER SYSTEM SET max_parallel_maintenance_workers = 4;

  03-create-monitoring-user.sql: |
    -- Create monitoring user for metrics
    DO $$
    BEGIN
      IF NOT EXISTS (SELECT FROM pg_user WHERE usename = 'metrics_user') THEN
        CREATE USER metrics_user WITH PASSWORD 'change-this-password';
      END IF;
    END
    $$;

    GRANT pg_monitor TO metrics_user;
    GRANT CONNECT ON DATABASE userdb TO metrics_user;
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: healthcare-backend
  labels:
    app: redis
    component: cache
data:
  redis.conf: |
    # Redis Production Configuration

    # Network
    bind 0.0.0.0
    protected-mode no
    port 6379
    tcp-backlog 511
    timeout 300
    tcp-keepalive 300

    # General
    daemonize no
    supervised no
    pidfile /var/run/redis_6379.pid
    loglevel notice
    logfile ""
    databases 16

    # Snapshotting
    save 900 1
    save 300 10
    save 60 10000
    stop-writes-on-bgsave-error yes
    rdbcompression yes
    rdbchecksum yes
    dbfilename dump.rdb
    dir /data

    # Cluster (enabled via overlays for staging/production)
    # cluster-enabled yes
    # cluster-config-file /data/nodes.conf
    # cluster-node-timeout 5000
    # cluster-allow-reads-when-down yes

    # Replication (used when cluster disabled)
    replica-serve-stale-data yes
    replica-read-only yes
    repl-diskless-sync no
    repl-diskless-sync-delay 5
    repl-disable-tcp-nodelay no
    replica-priority 100

    # Security
    # requirepass will be set via environment variable

    # Limits
    maxclients 10000
    maxmemory 2gb
    maxmemory-policy noeviction
    maxmemory-samples 5

    # Append Only Mode
    appendonly yes
    appendfilename "appendonly.aof"
    appendfsync everysec
    no-appendfsync-on-rewrite no
    auto-aof-rewrite-percentage 100
    auto-aof-rewrite-min-size 64mb
    aof-load-truncated yes
    aof-use-rdb-preamble yes

    # Lua scripting
    lua-time-limit 5000

    # Slow log
    slowlog-log-slower-than 10000
    slowlog-max-len 128

    # Latency monitor
    latency-monitor-threshold 100

    # Event notification
    notify-keyspace-events ""

    # Advanced config
    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    list-max-ziplist-size -2
    list-compress-depth 0
    set-max-intset-entries 512
    zset-max-ziplist-entries 128
    zset-max-ziplist-value 64
    hll-sparse-max-bytes 3000
    stream-node-max-bytes 4096
    stream-node-max-entries 100
    activerehashing yes
    client-output-buffer-limit normal 0 0 0
    client-output-buffer-limit replica 256mb 64mb 60
    client-output-buffer-limit pubsub 32mb 8mb 60
    hz 10
    dynamic-hz yes
    aof-rewrite-incremental-fsync yes
    rdb-save-incremental-fsync yes
